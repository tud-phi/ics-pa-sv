{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac408b5e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7619294def77410a539e618e2428f0d5",
     "grade": false,
     "grade_id": "cell-b00828259c8e42e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# RO47019: Intelligent Control Systems Practical Assignment\n",
    "* Period: 2023-2024, Q3\n",
    "* Course homepage: https://brightspace.tudelft.nl/d2l/home/500969\n",
    "* Instructor: Cosimo Della Santina (C.DellaSantina@tudelft.nl)\n",
    "* Teaching assistant: Maria de Neves de Fonseca (M.deNevesdeFonseca-1@student.tudelft.nl)\n",
    "* (c) TU Delft, 2024\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE`. Remove `raise NotImplementedError()` afterwards. Moreover, if you see an empty cell, please DO NOT delete it, instead run that cell as you would run all other cells. Please fill in your name(s) and other required details below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9e220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please fill in your names, student numbers, netID, and emails below.\n",
    "STUDENT_1_NAME = \"\"\n",
    "STUDENT_1_STUDENT_NUMBER = \"\"\n",
    "STUDENT_1_NETID = \"\"\n",
    "STUDENT_1_EMAIL = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba32571",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "042927213b84aa368aa3ea72caa4cb60",
     "grade": true,
     "grade_id": "cell-9f148ec62e0de49c",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note: this block is a check that you have filled in the above information.\n",
    "# It will throw an AssertionError until all fields are filled\n",
    "assert STUDENT_1_NAME != \"\"\n",
    "assert STUDENT_1_STUDENT_NUMBER != \"\"\n",
    "assert STUDENT_1_NETID != \"\"\n",
    "assert STUDENT_1_EMAIL != \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af317a94",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "95c5b11f9ac3896252d342cabb38d867",
     "grade": false,
     "grade_id": "cell-4ea391677951116c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### General announcements\n",
    "\n",
    "* Do *not* share your solutions (also after the course is finished), and do *not* copy solutions from others. By submitting your solutions, you claim that you alone are responsible for this code.\n",
    "\n",
    "* Do *not* email questions directly, since we want to provide everybody with the same information and avoid repeating the same answers. Instead, please post your questions regarding this assignment in the correct support forum on Brightspace, this way everybody can benefit from the response. If you do have a particular question that you want to ask directly, please use the scheduled Q&A hours to ask the TA.\n",
    "\n",
    "* There is a strict deadline for each assignment. Students are responsible to ensure that they have uploaded their work in time. So, please double check that your upload succeeded to the Brightspace and avoid any late penalties.\n",
    "\n",
    "* This [Jupyter notebook](https://jupyter.org/) uses `nbgrader` to help us with automated tests. `nbgrader` will make various cells in this notebook \"uneditable\" or \"unremovable\" and gives them a special id in the cell metadata. This way, when we run our checks, the system will check the existence of the cell ids and verify the number of points and which checks must be run. While there are ways that you can edit the metadata and work around the restrictions to delete or modify these special cells, you should not do that since then our nbgrader backend will not be able to parse your notebook and give you points for the assignment. You are free to add additional cells, but if you find a cell that you cannot modify or remove, please know that this is on purpose.\n",
    "\n",
    "* This notebook will have in various places a line that throws a `NotImplementedError` exception. These are locations where the assignment requires you to adapt the code! These lines are just there as a reminder for you that you have not yet adapted that particular piece of code, especially when you execute all the cells. Once your solution code replaced these lines, it should accordingly *not* throw any exceptions anymore.\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c956945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7dd65d04",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0e05c64784117f3d916054e90e7777a1",
     "grade": false,
     "grade_id": "cell-bb15951eb4749de1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Task 3a - Gaussian Process Regression (6p)\n",
    "**Authors:** Giovanni Franzese (G.Franzese@tudelft.nl), Lorenzo Lyons (L.Lyons@tudelft.nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c7686a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "06ab6f76bc4a0ea4d7543d19c70ca4ba",
     "grade": false,
     "grade_id": "cell-61889344b8180940",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Cheat sheet for Gaussian Process Regression (GPR) using the `gpytorch` library.\n",
    "Zero mean \n",
    "\n",
    "```python\n",
    "        gpytorch.means.ZeroMean()\n",
    "```\n",
    "\n",
    "Constant mean\n",
    "\n",
    "```python\n",
    "        gpytorch.means.ConstantMean()\n",
    "```\n",
    "\n",
    "RBF kernel\n",
    "\n",
    "```python\n",
    "        gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "```\n",
    "\n",
    "Matern kernel\n",
    "\n",
    "```python\n",
    "        gpytorch.kernels.ScaleKernel(gpytorch.kernels.MaternKernel())\n",
    "```\n",
    "\n",
    "RBF with ARD\n",
    "\n",
    "```python\n",
    "        gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=n)) # where n is the number of features of the inptus\n",
    "```\n",
    "\n",
    "Gaussian likelihood \n",
    "        \n",
    "```python\n",
    "        gpytorch.likelihoods.GaussianLikelihood()\n",
    "```\n",
    "\n",
    "Maximum Likelihood Estimation (MLE) \n",
    "\n",
    "```python\n",
    "        gpytorch.mlls.ExactMarginalLogLikelihood()\n",
    "```\n",
    "\n",
    "Makine prediction with Gaussian Process p(f*|x*,X,Y)\n",
    "\n",
    "```python\n",
    "        model.eval()\n",
    "        with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "            predictions = model(test_x)\n",
    "            mean = predictions.mean\n",
    "            lower, upper = predictions.confidence_region()\n",
    "            std = predictions.stddev\n",
    "            var = predictions.variance\n",
    "```\n",
    "\n",
    "Makine prediction with Gaussian Process p(y*|x*,X,Y)\n",
    "\n",
    "```python\n",
    "        model.eval()\n",
    "        with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "            predictions = likelihood(model(test_x))\n",
    "```\n",
    "\n",
    "```python\n",
    "   \n",
    "```\n",
    "Print the learned horizontal lenghtscales\n",
    "        \n",
    "```python\n",
    "        model.covar_module.base_kernel.lengthscale\n",
    "```\n",
    "\n",
    "Print the learned vertical lenghtscales\n",
    "        \n",
    "```python\n",
    "        model.covar_module.raw_outputscale\n",
    "```\n",
    "\n",
    "Print the learned noise\n",
    "        \n",
    "```python\n",
    "        model.likelihood.noise\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab406fb6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a0fb160a8e40201362e75ec75d63ab17",
     "grade": false,
     "grade_id": "cell-3de645494cd1bff9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Load the tensile analysis sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57bc443",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c3f3c94cf693e106983300aea433e88",
     "grade": false,
     "grade_id": "cell-d0a9a3d67dd482d0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# load panda framework from txt file the first row is the header\n",
    "# Dataset from: https://mtil.illinois.edu/DATA/_DataAnalysisHELP/_Tensile_Example/Tensile_Analysis/6150_Tensile_Data/\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "steel = pd.read_csv(Path(\"datasets\") / \"tensile_strenght.txt\", sep=\"\\t\", header=1)\n",
    "steel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2736d9a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "30a57703025a7e8f12de232de0f08ecf",
     "grade": false,
     "grade_id": "cell-4816fa0ff37339eb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X = steel[\"Position(mm)\"].to_numpy()[:-1]\n",
    "Y = steel[\"Load(kN)\"].to_numpy()[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96b87a3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "adec11b5901de5e96961887adf8a3188",
     "grade": false,
     "grade_id": "cell-8a64ced849f26797",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# define folder where to save animations and plots\n",
    "outputs_dir = Path(\"outputs\")\n",
    "outputs_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "plt.plot(X, Y, \"o\", color=\"red\")\n",
    "plt.xlabel(\"Position(mm)\")\n",
    "plt.ylabel(\"Load(kN)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e05859",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4e3a777e5949d56dcb6399b7e28aa62c",
     "grade": false,
     "grade_id": "cell-0b5c8e209a090392",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 3a.1 - Fit the data with an Exact Gaussian Process (2.5p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b768eed",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "14b997a809aaedce400232c40ac02d74",
     "grade": false,
     "grade_id": "cell-9b1b9b007c17f0df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Definition of the model class (1p)\n",
    "Define the Exact Gaussian Process Model with a zero mean and RBF kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684a273d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9b56ece873d16b358b2195a0062269c3",
     "grade": true,
     "grade_id": "cell-809985702b151f64",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.notebook import tqdm  # progress bar\n",
    "\n",
    "\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        # Use zero mean and covariance modules as the rbf kernel\n",
    "        # self.mean_module\n",
    "        # self.covar_module\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123ac87b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f70f32e45f45bdb0f9febfadef3afcf3",
     "grade": false,
     "grade_id": "cell-09852e40c954d0bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Train the model (1p)\n",
    "Define the likelihood to be Gaussian, the model to be the Exact GP defined in the previous step, and the Marginal log-likelihood as a cost function to optimize the kernel function's hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607af340",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fd857bed6a5116a6994f0d339bb7c420",
     "grade": true,
     "grade_id": "cell-62cd203d1e53a21f",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# set random seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "train_x = torch.tensor(X)\n",
    "train_y = torch.tensor(Y)\n",
    "\n",
    "# initialize likelihood and model\n",
    "# exact_likelihood =\n",
    "# exact_model =\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "exact_model.train()\n",
    "exact_likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    exact_model.parameters(), lr=0.1\n",
    ")  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "# marginal_mll =\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "num_epochs = 500\n",
    "for i in (pbar := tqdm(range(num_epochs))):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = exact_model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    # we minimize the negaitive log likelihood that is the same as maximizing the log likelihood\n",
    "    loss = -marginal_mll(output, train_y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    pbar.set_description(\n",
    "        \"Loss: %.3f, lengthscale: %.3f, noise: %.3f\"\n",
    "        % (\n",
    "            loss.item(),\n",
    "            exact_model.covar_module.base_kernel.lengthscale.item(),\n",
    "            exact_model.likelihood.noise.item(),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cd03b0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "931a618ec62dde12d98166be4891988f",
     "grade": false,
     "grade_id": "cell-2b8043e13938e860",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Get into evaluation (predictive posterior) mode\n",
    "exact_model.eval()\n",
    "exact_likelihood.eval()\n",
    "\n",
    "# Make predictions by feeding model through likelihood\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.linspace(torch.min(train_x), torch.max(train_x), 100).double()\n",
    "    observed_pred = exact_likelihood(exact_model(test_x))\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Initialize plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "    plt.xlabel(\"Position(mm)\")\n",
    "    plt.ylabel(\"Load(kN)\")\n",
    "    # Get upper and lower confidence bounds\n",
    "    lower, upper = observed_pred.confidence_region()\n",
    "    # Plot training data as black stars\n",
    "    ax.plot(train_x.numpy(), train_y.numpy(), \"ro\")\n",
    "    # Plot predictive means as blue line\n",
    "    ax.plot(test_x.numpy(), observed_pred.mean.numpy(), \"b\")\n",
    "    # Shade between the lower and upper confidence bounds\n",
    "    ax.fill_between(test_x.numpy(), lower.numpy(), upper.numpy(), alpha=0.5)\n",
    "    ax.legend([\"Observed Data\", \"Mean\", \"Confidence\"])\n",
    "    fig.savefig(outputs_dir / \"task_3a-1_load_vs_position.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f1cb25",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "43d48770e72072487c8677cdaa23e24e",
     "grade": false,
     "grade_id": "cell-e46610e37de3efb3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Extraction of the length scales and the likelihood noise (0.5p)\n",
    "Print the horizontal and vertical length scales and the likelihood noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3ff4e5",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b900103a458061bafce6c0d9d689828b",
     "grade": true,
     "grade_id": "cell-60684f26b87d98c2",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# print(\"Horizontal lengthscales:\", YOUR_CODE)\n",
    "# print(\"Vertical lengthscales:\", YOUR_CODE)\n",
    "# print(\"Likelihood noise:\", YOUR_CODE)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eff408",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7070dddffc7e8d82d44230be68c6fbd8",
     "grade": false,
     "grade_id": "cell-72e3d0804cf83a26",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 3a.2 - Fit the curve using only a reduced set of inducing points using Sparse Variational Gaussian Process (3.5p)\n",
    "The Stochastic Variational Gaussian Process (SVGP) is a sparse approximation of the Exact GP. The SVGP model is defined by selecting a set of inducing points and optimizing the hyperparameters of the kernel function and the inducing points. The structure of the model is similar to an exact GP but has additional variables that are optimized during training, i.e., the inducing points, and the cost function is the Evidence Lower Bound (ELBO) instead of the Marginal log-likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d5af7d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "86d90ba208d802fad7d38a628d52198d",
     "grade": false,
     "grade_id": "cell-431b23f66c2b0cca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Cheat sheet for Sparse Variational Gaussian Process (SVGP) (0p)\n",
    "Gaussian likelihood \n",
    "\n",
    "Expected Variational lower bound of the maximum likelihood to use as an alternative to the MLE\n",
    "\n",
    "```python\n",
    "        elbo_mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=train_y.size(0))\n",
    "```\n",
    "where the train_y.size(0) is the number of training samples; this number is used to scale the ELBO to the same scale as the MLE.\n",
    "\n",
    "Print the learned inducting points:\n",
    "        \n",
    "```python\n",
    "        model.variational_strategy.inducing_points\n",
    "```\n",
    "\n",
    "The likelihood and the kernel are the same as the exact GP model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd08cea",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7e0bf64122ddd8eb9bf61e0c708dc107",
     "grade": false,
     "grade_id": "cell-29d46807ac5f9c3e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Choose the model to be an SVGP model where you select 10 inducing points equally spaced along the x-axis.  (3p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc734d1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b1f2179f0badc1af52181b59bf99b17c",
     "grade": false,
     "grade_id": "cell-52802329306c0ccd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Define the `SVGPModel` (0.5p)\n",
    "Choose the mean and the kernel in the definition of the model as in the previous task, i.e., zero mean and RBF kernel (0.5p)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ab4bf7",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a74f24e56317a8cdcb59e9660d841aa2",
     "grade": true,
     "grade_id": "cell-766e731b16774e09",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from gpytorch.models import ApproximateGP\n",
    "from gpytorch.variational import CholeskyVariationalDistribution\n",
    "from gpytorch.variational import VariationalStrategy\n",
    "\n",
    "# set random seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "class SVGPModel(ApproximateGP):\n",
    "    def __init__(self, inducing_points):\n",
    "        variational_distribution = CholeskyVariationalDistribution(\n",
    "            inducing_points.size(0)\n",
    "        )\n",
    "        variational_strategy = VariationalStrategy(\n",
    "            self,\n",
    "            inducing_points,\n",
    "            variational_distribution,\n",
    "            learn_inducing_locations=True,\n",
    "        )\n",
    "        super(SVGPModel, self).__init__(variational_strategy)\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd6f7f6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "85b6ba13f3544237b8c2cad422b56651",
     "grade": false,
     "grade_id": "cell-a229743e59175af1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Select inducing points (1p)\n",
    "Choose ten inducing points equally spaced along the x-axis, initialize the model as an SVGP as defined above, and choose the likelihood to be Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec2ebd2",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd389f069921099a3b7e9a49a23dce96",
     "grade": true,
     "grade_id": "cell-3b419039fdb3e20f",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# inducing_points = YOUR_CODE\n",
    "# initialize model and likelihood\n",
    "# svgp_model = YOUR_CODE\n",
    "# svgp_likelihood = YOUR_CODE\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "svgp_model = svgp_model.double()\n",
    "svgp_likelihood = svgp_likelihood.double()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a413857",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9e61e7c48ddb58c0e598dd250e2adb61",
     "grade": false,
     "grade_id": "cell-1ef1f602822eb24f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Train the model (0.5p)\n",
    "Define the cost function as ELBO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a150be",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5953f32c60c3d7e4e0ddcaaae40355da",
     "grade": true,
     "grade_id": "cell-659e66ac49c8c9df",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "svgp_model.train()\n",
    "svgp_likelihood.train()\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    [\n",
    "        {\"params\": svgp_model.parameters()},\n",
    "        {\"params\": svgp_likelihood.parameters()},\n",
    "    ],\n",
    "    lr=0.01,\n",
    ")\n",
    "\n",
    "\n",
    "# Our loss object. We're using the VariationalELBO rather than the ExactMarginalLogLikelihood.\n",
    "# elbo_mll =\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "\n",
    "num_epochs = 10000\n",
    "for i in tqdm(range(num_epochs)):\n",
    "    # Within each iteration, we will go over each minibatch of data\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = svgp_model(x_batch)\n",
    "        loss = -elbo_mll(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab38d3a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "98a4764fb26c143aba772d013250b74c",
     "grade": false,
     "grade_id": "cell-d97056d0aa894f13",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Test the trained model (1p)\n",
    "Define the test points as 100 equally spaced points between 0 and max of the training data. Then, evaluate p(y*|x*,X,Y) for the test points. Finally, save the optimized inducing points in a new vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b9059d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dadaa58bfe09737c60105f87dbf11daa",
     "grade": true,
     "grade_id": "cell-e8a0c3c53003c4c1",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Get into evaluation (predictive posterior) mode\n",
    "svgp_model.eval()\n",
    "svgp_likelihood.eval()\n",
    "\n",
    "# Test points are regularly spaced along [0,1]\n",
    "# Make predictions by feeding model through likelihood\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    # test_x =\n",
    "    # observed_pred =\n",
    "    # inducing_inputs =\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f79e833",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5a33f9509903badd06a646ae6f71c570",
     "grade": false,
     "grade_id": "cell-d277cf14d26cd654",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # Initialize plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "    plt.xlabel(\"Position(mm)\")\n",
    "    plt.ylabel(\"Load(kN)\")\n",
    "    # Get upper and lower confidence bounds\n",
    "    lower, upper = observed_pred.confidence_region()\n",
    "    # Plot training data as black stars\n",
    "    ax.plot(train_x.numpy(), train_y.numpy(), \"ro\")\n",
    "    # Plot predictive means as blue line\n",
    "    ax.plot(test_x.numpy(), observed_pred.mean.numpy(), \"b\")\n",
    "    # Shade between the lower and upper confidence bounds\n",
    "    ax.fill_between(test_x.numpy(), lower.numpy(), upper.numpy(), alpha=0.5)\n",
    "    plt.scatter(\n",
    "        inducing_inputs.numpy(),\n",
    "        np.zeros_like(inducing_inputs.numpy()),\n",
    "        color=\"k\",\n",
    "        marker=\"x\",\n",
    "        s=50,\n",
    "        zorder=10,\n",
    "        label=\"Inducing Inputs\",\n",
    "    )\n",
    "    ax.legend([\"Observed Data\", \"Mean\", \"Confidence\", \"Inducing Inputs\"])\n",
    "    fig.savefig(outputs_dir / \"task_3a-2_load_vs_position.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5887788",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6ad0fe35e83ac061a6bf569e5f1383af",
     "grade": false,
     "grade_id": "cell-3ea59cd345d73c38",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Extraction of the length scales and the likelihood noise (0.5p)\n",
    "Print the the horizontal and vertical lengthscale and the noise of the learned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf706fa",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b6e2eb0962fc32a470b9d212226d84f8",
     "grade": true,
     "grade_id": "cell-775f1b0f6a3db010",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# print(\"Horizontal lengthscale:\", YOUR_CODE)\n",
    "# print(\"Vertical lengthscale:\", YOUR_CODE)\n",
    "# print(\"Likelihood:\", YOUR_CODE)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
